{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: dumbbells.txt\n",
      "(299, 72)\n",
      "Processing: face_wipe.txt\n",
      "(299, 72)\n",
      "Processing: left.txt\n",
      "(299, 72)\n",
      "Processing: muscle.txt\n",
      "(299, 72)\n",
      "Processing: nothing.txt\n",
      "(299, 72)\n",
      "Processing: pac_man.txt\n",
      "(299, 72)\n",
      "Processing: right.txt\n",
      "(299, 72)\n",
      "Processing: shooting_star.txt\n",
      "(299, 72)\n",
      "Processing: shout_out.txt\n",
      "(299, 72)\n",
      "Processing: tornado.txt\n",
      "(299, 72)\n",
      "Processing: weight_lifting.txt\n",
      "(299, 72)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn import Module\n",
    "import torch.nn.functional as F\n",
    "import brevitas.nn as qnn\n",
    "from brevitas.core.quant import QuantType\n",
    "from CG4002.MachineLearning.main_code.util_main import load_dance_dance_data_set\n",
    "from CG4002.MachineLearning.main_code.util_main import test_model_nn\n",
    "from CG4002.MachineLearning.main_code.util_main import load_model as load_model_keras\n",
    "from CG4002.MachineLearning.main_code.util_main import one_hot_encode_labels\n",
    "import torch \n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "data_set_path = \"CG4002/MachineLearning/main_code/Data-sets/Dance_Data\"\n",
    "sampling_rate = 5\n",
    "window_length = 2.56  # Seconds\n",
    "\n",
    "#load data set\n",
    "x_data, y_data = load_dance_dance_data_set(data_set_path, sampling_rate=sampling_rate, window_length=window_length)\n",
    "\n",
    "x_data, y_data = shuffle(x_data, y_data)\n",
    "y_data = y_data - 1\n",
    "\n",
    "x_train_data, x_test_data = x_data[:int(len(x_data)*0.7), :], x_data[int(len(x_data)*0.7):, :]\n",
    "y_train_data, y_test_data = y_data[:int(len(x_data)*0.7), :], y_data[int(len(x_data)*0.7):, :]\n",
    "#y_data = one_hot_encode_labels(y_data)\n",
    "\n",
    "x_train = torch.from_numpy(x_train_data).float()\n",
    "y_train = torch.from_numpy(y_train_data).float()\n",
    "y_train = y_train.reshape(y_train.shape[0]).long()\n",
    "\n",
    "x_test = torch.from_numpy(x_test_data).float()\n",
    "y_test = torch.from_numpy(y_test_data).float()\n",
    "y_test = y_test.reshape(y_test.shape[0]).long()\n",
    "\n",
    "input_dim = x_data.shape[1]\n",
    "output_dim = one_hot_encode_labels(y_data).shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('inputs.npy', x_data, allow_pickle=False, fix_imports=False)\n",
    "np.save('labels.npy', y_data, allow_pickle=False, fix_imports=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "#hardtanh version\n",
    "class MLP_quantized_exportable(Module):\n",
    "    def __init__(self):\n",
    "        super(MLP_quantized_exportable, self).__init__()\n",
    "        self.input   = qnn.QuantLinear(input_dim, 256, bias=False, \n",
    "                                     weight_quant_type=QuantType.INT, \n",
    "                                     weight_bit_width=8)\n",
    "        self.input_relu = qnn.QuantHardTanh(quant_type=QuantType.INT, bit_width=4)\n",
    "        \n",
    "        self.h1   = qnn.QuantLinear(256, 256, bias=False, \n",
    "                                     weight_quant_type=QuantType.INT, \n",
    "                                     weight_bit_width=8)\n",
    "        self.relu1 = qnn.QuantHardTanh(quant_type=QuantType.INT, bit_width=4)\n",
    "        \n",
    "        self.h2   = qnn.QuantLinear(256, 128, bias=False, \n",
    "                                     weight_quant_type=QuantType.INT, \n",
    "                                     weight_bit_width=8)\n",
    "        self.relu2 = qnn.QuantHardTanh(quant_type=QuantType.INT, bit_width=4)\n",
    "        \n",
    "        self.h3   = qnn.QuantLinear(128, output_dim, bias=False, \n",
    "                                     weight_quant_type=QuantType.INT, \n",
    "                                     weight_bit_width=4)\n",
    "\n",
    "        self.output   = qnn.QuantSigmoid(quant_type=QuantType.FP, bit_width=8)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.input(x)\n",
    "        x = self.input_relu(x)\n",
    "        \n",
    "        x = self.h1(x)\n",
    "        x = self.relu1(x)\n",
    "        \n",
    "        x = self.h2(x)\n",
    "        x = self.relu2(x)\n",
    "        \n",
    "        x = self.h3(x)\n",
    "        return self.output(x)\n",
    "    \n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils import data\n",
    "model = MLP_quantized_exportable()\n",
    "\n",
    "class Dataset_custom(data.Dataset):\n",
    "  'Characterizes a dataset for PyTorch'\n",
    "  def __init__(self, inputs, labels):\n",
    "        'Initialization'\n",
    "        self.labels = labels\n",
    "        self.inputs = inputs\n",
    "\n",
    "  def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.inputs)\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "        # Load data and get label\n",
    "        x = self.inputs[index]\n",
    "        y = self.labels[index]\n",
    "\n",
    "        return x, y\n",
    "    \n",
    "train_dataset = Dataset_custom(x_train, y_train) # create your dataset\n",
    "train_loader = data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_dataset = Dataset_custom(x_test, y_test) # create your dataset\n",
    "test_loader = data.DataLoader(test_dataset, batch_size=32)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Results - Epoch: 1  Avg accuracy: 0.91 Avg loss: 1.57\n",
      "Validation Results - Epoch: 1  Avg accuracy: 0.89 Avg loss: 1.57\n",
      "Training Results - Epoch: 2  Avg accuracy: 0.91 Avg loss: 1.56\n",
      "Validation Results - Epoch: 2  Avg accuracy: 0.89 Avg loss: 1.57\n",
      "Training Results - Epoch: 3  Avg accuracy: 0.94 Avg loss: 1.57\n",
      "Validation Results - Epoch: 3  Avg accuracy: 0.94 Avg loss: 1.58\n",
      "Training Results - Epoch: 4  Avg accuracy: 0.92 Avg loss: 1.57\n",
      "Validation Results - Epoch: 4  Avg accuracy: 0.91 Avg loss: 1.58\n",
      "Training Results - Epoch: 5  Avg accuracy: 0.93 Avg loss: 1.56\n",
      "Validation Results - Epoch: 5  Avg accuracy: 0.92 Avg loss: 1.58\n"
     ]
    }
   ],
   "source": [
    "from ignite.engine import Events, create_supervised_trainer, create_supervised_evaluator\n",
    "from ignite.metrics import Accuracy, Loss\n",
    "from ignite.handlers import EarlyStopping\n",
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "\n",
    "def score_function(engine):\n",
    "    val_loss = engine.state.metrics['crossentropy']\n",
    "    accuracy = engine.state.metrics['accuracy']\n",
    "    return accuracy #-val_loss\n",
    "\n",
    "\n",
    "\n",
    "trainer = create_supervised_trainer(model, optimizer, loss)\n",
    "evaluator = create_supervised_evaluator(model,\n",
    "                                        metrics={\n",
    "                                            'accuracy': Accuracy(),\n",
    "                                            'crossentropy': Loss(loss)\n",
    "                                            })\n",
    "\n",
    "handler = EarlyStopping(patience=5, score_function=score_function, trainer=trainer)\n",
    "# Note: the handler is attached to an *Evaluator* (runs one epoch on validation dataset).\n",
    "evaluator.add_event_handler(Events.COMPLETED, handler)\n",
    "\n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def log_training_results(trainer):\n",
    "    evaluator.run(train_loader)\n",
    "    metrics = evaluator.state.metrics\n",
    "    print(\"Training Results - Epoch: {}  Avg accuracy: {:.2f} Avg loss: {:.2f}\"\n",
    "          .format(trainer.state.epoch, metrics['accuracy'], metrics['crossentropy']))\n",
    "\n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def log_validation_results(trainer):\n",
    "    evaluator.run(test_loader)\n",
    "    metrics = evaluator.state.metrics\n",
    "    print(\"Validation Results - Epoch: {}  Avg accuracy: {:.2f} Avg loss: {:.2f}\"\n",
    "          .format(trainer.state.epoch, metrics['accuracy'], metrics['crossentropy']))\n",
    "\n",
    "trainer.run(train_loader, max_epochs=35)\n",
    "\n",
    "torch.save(model.state_dict(), \"quantized_statedict_exportable.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
