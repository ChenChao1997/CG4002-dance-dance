{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup to allow resume at any step\n",
    "#Note: Copy tmp folder to retain data\n",
    "#To start running from any cells, run this setup cell first\n",
    "#Necessary\n",
    "import inspect\n",
    "import netron\n",
    "from finn.util.basic import make_build_dir\n",
    "from IPython.display import IFrame\n",
    "import onnx\n",
    "import brevitas.onnx as bo\n",
    "from finn.util.basic import pynq_part_map\n",
    "from pkgutil import get_data\n",
    "import onnx.numpy_helper as nph\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from finn.core.onnx_exec import execute_onnx\n",
    "\n",
    "#API for model tidy up and HLS synthesis\n",
    "from finn.core.modelwrapper import ModelWrapper\n",
    "from finn.transformation.general import GiveReadableTensorNames, GiveUniqueNodeNames\n",
    "from finn.transformation.infer_shapes import InferShapes\n",
    "from finn.transformation.infer_datatypes import InferDataTypes\n",
    "from finn.transformation.fold_constants import FoldConstants\n",
    "from finn.transformation.streamline import Streamline\n",
    "from finn.transformation.bipolar_to_xnor import ConvertBipolarMatMulToXnorPopcount\n",
    "import finn.transformation.streamline.absorb as absorb\n",
    "from finn.transformation.streamline.round_thresholds import RoundAndClipThresholds\n",
    "import finn.transformation.fpgadataflow.convert_to_hls_layers as to_hls\n",
    "from finn.transformation.fpgadataflow.create_dataflow_partition import CreateDataflowPartition\n",
    "from finn.custom_op.registry import getCustomOp\n",
    "from finn.transformation.fpgadataflow.insert_tlastmarker import InsertTLastMarker\n",
    "from finn.transformation.fpgadataflow.codegen_ipgen import CodeGen_ipgen\n",
    "from finn.transformation.fpgadataflow.hlssynth_ipgen import HLSSynth_IPGen\n",
    "from finn.transformation.fpgadataflow.codegen_ipstitch import CodeGen_ipstitch\n",
    "from finn.transformation.fpgadataflow.replace_verilog_relpaths import ReplaceVerilogRelPaths\n",
    "from finn.transformation.fpgadataflow.make_pynq_proj import MakePYNQProject\n",
    "from finn.transformation.fpgadataflow.synth_pynq_proj import SynthPYNQProject\n",
    "from finn.transformation.fpgadataflow.make_pynq_driver import MakePYNQDriver\n",
    "from finn.transformation.fpgadataflow.make_deployment import DeployToPYNQ\n",
    "\n",
    "#For pretrained network\n",
    "from pkgutil import get_data\n",
    "from finn.util.test import get_test_model_trained\n",
    "\n",
    "#Code inspecction for debugging\n",
    "def showSrc(what):\n",
    "    print(\"\".join(inspect.getsourcelines(what)[0]))\n",
    "    \n",
    "#Vizulization for design recheck\n",
    "def showInNetron(model_filename):\n",
    "    netron.start(model_filename, port=8081, host=\"0.0.0.0\")\n",
    "    return IFrame(src=\"http://0.0.0.0:8081/\", width=\"100%\", height=400)\n",
    "\n",
    "#All HLS files location: Workspace default is mounted to /tmp/\n",
    "build_dir = \"/workspace/finn\"\n",
    "model_name = build_dir + \"/sfc_w1_a1\"\n",
    "model_extension = \".onnx\"\n",
    "\n",
    "#Board definition\n",
    "pynq_board = \"Ultra96\"\n",
    "fpga_part = pynq_part_map[pynq_board]\n",
    "target_clk_ns = 5\n",
    "ip = \"192.168.3.1\"\n",
    "username = \"xilinx\"\n",
    "password = \"xilinx\"\n",
    "target_dir = \"/home/xilinx/dance_dance\"\n",
    "\n",
    "#all model name use in the process\n",
    "model_name_original = model_name + model_extension\n",
    "model_name_tidy = model_name + \"_tidy\" +  model_extension\n",
    "model_name_streamlined = model_name + \"_streamlined\" +  model_extension\n",
    "model_name_hls_ready = model_name + \"_hls_ready\" +  model_extension\n",
    "model_name_hls_layers = model_name + \"_hls_layers\" +  model_extension\n",
    "model_name_data_flow = model_name + \"_dataflow_parent\" +  model_extension \n",
    "model_name_set_folding = model_name + \"_set_folding\" + model_extension\n",
    "model_name_ipgen = model_name + \"_ipgen\" + model_extension\n",
    "model_name_ipstitch = model_name + \"_ipstitch\" + model_extension\n",
    "model_name_pynq_proj = model_name + \"_pynq_project\" + model_extension\n",
    "model_name_post_synthesis = model_name + \"_post_synthesis\" + model_extension\n",
    "model_name_deploy = model_name + \"_deploy\" + model_extension\n",
    "model_name_deploy_integrated = model_name + \"_deploy_integrated\" + model_extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load model and weight, can skip with mode already export as onnx\n",
    "tfc = get_test_model_trained(\"TFC\", 1, 1)\n",
    "bo.export_finn_onnx(tfc, (1, 1, 28, 28), model_name + model_extension)\n",
    "showInNetron(build_dir+\"/tfc_w1_a1.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model tidy up\n",
    "\n",
    "model = ModelWrapper(model_name_original)\n",
    "model = model.transform(InferShapes())\n",
    "model = model.transform(FoldConstants())\n",
    "model = model.transform(GiveUniqueNodeNames())\n",
    "model = model.transform(GiveReadableTensorNames())\n",
    "model = model.transform(InferDataTypes())\n",
    "\n",
    "model.save(model_name_tidy)\n",
    "showInNetron(model_name_tidy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model streamline\n",
    "model = ModelWrapper(model_name_tidy)\n",
    "model = model.transform(Streamline())\n",
    "model.save(model_name_streamlined)\n",
    "showInNetron(model_name_streamlined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model HLS conversion prepare, need to modified for 8 bit quantization, current 1 bit polar\n",
    "model = ModelWrapper(model_name_streamlined)\n",
    "model = model.transform(ConvertBipolarMatMulToXnorPopcount())\n",
    "model = model.transform(absorb.AbsorbAddIntoMultiThreshold())\n",
    "model = model.transform(absorb.AbsorbMulIntoMultiThreshold())\n",
    "model = model.transform(RoundAndClipThresholds())\n",
    "\n",
    "model.save(model_name_hls_ready)\n",
    "showInNetron(model_name_hls_ready)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model HLS layers conversion, need to fix depend on quantization type\n",
    "model = ModelWrapper(model_name_hls_ready)\n",
    "model = model.transform(to_hls.InferBinaryStreamingFCLayer())\n",
    "model.save(model_name_hls_layers)\n",
    "showInNetron(model_name_hls_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model create dataflow partition \n",
    "model = ModelWrapper(model_name_hls_layers)\n",
    "parent_model = model.transform(CreateDataflowPartition())\n",
    "parent_model.save(model_name_data_flow)\n",
    "showInNetron(model_name_data_flow)\n",
    "\n",
    "#To show child dataflow layer that are wrap together in the parent graph\n",
    "#Use to check if process finished correctly\n",
    "sdp_node = getCustomOp(parent_model.graph.node[2]) #need to change here depend on the graph\n",
    "dataflow_model_filename = sdp_node.get_nodeattr(\"model\")\n",
    "showInNetron(dataflow_model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stream layers folding\n",
    "parent_model = ModelWrapper(model_name_data_flow)\n",
    "sdp_node = getCustomOp(parent_model.graph.node[2]) #need to change here depend on the graph\n",
    "dataflow_model_filename = sdp_node.get_nodeattr(\"model\")\n",
    "\n",
    "model = ModelWrapper(dataflow_model_filename)\n",
    "\n",
    "#Extract all StreamingFCLayer_Batch to assign folding, in the testing model is 4 layers\n",
    "fc0 = model.graph.node[0]\n",
    "fc1 = model.graph.node[1]\n",
    "fc2 = model.graph.node[2]\n",
    "fc3 = model.graph.node[3]\n",
    "\n",
    "fc0w = getCustomOp(fc0)\n",
    "fc1w = getCustomOp(fc1)\n",
    "fc2w = getCustomOp(fc2)\n",
    "fc3w = getCustomOp(fc3)\n",
    "\n",
    "#Set depend on paper experiment result and actual network\n",
    "fc0w.set_nodeattr(\"inFIFODepth\", 50)\n",
    "fc0w.set_nodeattr(\"SIMD\", 16)\n",
    "fc0w.set_nodeattr(\"PE\", 16)\n",
    "fc0w.set_nodeattr(\"outFIFODepth\", 4)\n",
    "\n",
    "fc1w.set_nodeattr(\"SIMD\", 16)\n",
    "fc1w.set_nodeattr(\"PE\", 16)\n",
    "fc1w.set_nodeattr(\"outFIFODepth\", 4)\n",
    "\n",
    "fc2w.set_nodeattr(\"SIMD\", 16)\n",
    "fc2w.set_nodeattr(\"PE\", 16)\n",
    "fc2w.set_nodeattr(\"outFIFODepth\", 4)\n",
    "\n",
    "fc3w.set_nodeattr(\"SIMD\", 16)\n",
    "fc3w.set_nodeattr(\"PE\", 10)\n",
    "fc3w.set_nodeattr(\"outFIFODepth\", 50)\n",
    "\n",
    "model = model.transform(InsertTLastMarker())\n",
    "model.save(model_name_set_folding)\n",
    "showInNetron(model_name_set_folding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HLS code generation and synthesis\n",
    "model = ModelWrapper(model_name_set_folding)\n",
    "model = model.transform(GiveUniqueNodeNames())\n",
    "model = model.transform(CodeGen_ipgen(fpga_part, target_clk_ns))\n",
    "\n",
    "model = model.transform(HLSSynth_IPGen())\n",
    "model.save(model_name_ipgen)\n",
    "showInNetron(model_name_ipgen)\n",
    "\n",
    "#For debugging\n",
    "# fc0w = getCustomOp(model.graph.node[0])\n",
    "# code_gen_dir = fc0w.get_nodeattr(\"code_gen_dir_ipgen\")\n",
    "# !ls {code_gen_dir}\n",
    "\n",
    "# shell_script = code_gen_dir + \"/ipgen.sh\"\n",
    "# !cat {shell_script}\n",
    "\n",
    "# tcl_script = code_gen_dir + \"/hls_syn_StreamingFCLayer_Batch_0.tcl\"\n",
    "# !cat {tcl_script}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IP stitching, a.k.a block design. This will create a vivado project with block condition that can be view and modified\n",
    "model = ModelWrapper(model_name_ipgen)\n",
    "model = model.transform(ReplaceVerilogRelPaths())\n",
    "model = model.transform(CodeGen_ipstitch(fpga_part))\n",
    "\n",
    "#model.model.metadata_props\n",
    "#model.get_metadata_prop(\"vivado_stitch_proj\")\n",
    "\n",
    "model.save(model_name_ipstitch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create PYNQ overlay\n",
    "model = ModelWrapper(model_name_ipstitch)\n",
    "model = model.transform(MakePYNQProject(pynq_board))\n",
    "\n",
    "#model.model.metadata_props\n",
    "#! ls {model.get_metadata_prop(\"vivado_pynq_proj\")}\n",
    "\n",
    "model.save(model_name_pynq_proj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bitstream synthesis, really really long\n",
    "model = ModelWrapper(model_name_pynq_proj)\n",
    "model = model.transform(SynthPYNQProject())\n",
    "\n",
    "#model.model.metadata_props\n",
    "\n",
    "model.save(model_name_post_synthesis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Driver generation to load bitfile to Ultra96 and deploy to the board\n",
    "model = ModelWrapper(build_dir + \"/tfc_w1_a1_post_synthesis.onnx\")\n",
    "model = model.transform(MakePYNQDriver())\n",
    "\n",
    "# driver_dir = model.get_metadata_prop(\"pynq_driver_dir\")\n",
    "# ! cat {driver_dir}/driver.py\n",
    "\n",
    "model = model.transform(DeployToPYNQ(ip, username, password, target_dir))\n",
    "model.save(model_name_deploy)\n",
    "\n",
    "#model.model.metadata_props\n",
    "#! sshpass -p {password} ssh {username}@{ip} 'ls -l {target_dir}/*'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load pre_processed data here for testing, will use Kynwhye scripts\n",
    "raw_i = get_data(\"finn\", \"data/onnx/mnist-conv/test_data_set_0/input_0.pb\")\n",
    "x = nph.to_array(onnx.load_tensor_from_string(raw_i))\n",
    "plt.imshow(x.reshape(28,28), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace StreamBatchLayer_wrapper with the deploy model\n",
    "parent_model = ModelWrapper(model_name_data_flow)\n",
    "sdp_node = parent_model.graph.node[2]\n",
    "remote_exec_model = model_name_deploy\n",
    "getCustomOp(sdp_node).set_nodeattr(\"model\", remote_exec_model)\n",
    "parent_model.save(model_name_deploy_integrated)\n",
    "\n",
    "iname = parent_model.graph.input[0].name\n",
    "oname = parent_model.graph.output[0].name\n",
    "ishape = parent_model.get_tensor_shape(iname)\n",
    "input_dict = {iname: x.reshape(ishape)}\n",
    "ret = execute_onnx(parent_model, input_dict, True)\n",
    "\n",
    "#Output function for classification task\n",
    "def softmax(x):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum()\n",
    "\n",
    "logits = ret[oname].flatten()\n",
    "prob = softmax(logits)\n",
    "\n",
    "plt.bar(np.arange(10), prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
